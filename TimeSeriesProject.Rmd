---
title: "Measuring Levels of Ozone Concentration (PPM) in Downtown Los Angeles"
author: "Philip Carey"
date: "6/04/2021"
output:
  default: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      eval = T,
                      message = F,
                      warning = F,
                      fig.height = 4,
                      fig.width = 6,
                      fig.align = 'center')
library(tidyverse)
library(modelr)
library(dplyr)
library(ggplot2)
library(ggfortify)
library(readr)
library(tsdl)
library(astsa)
library(MASS)
library(MuMIn)
library(forecast)
```


# Introduction

The basis of this report is to monitor the concentration of ozone in the atmosphere of downtown Los Angeles. Concentrations are measured in parts per million (ppm) between the years of 1955 and 1972 on a monthly basis, creating a time series of 216 observations. For the sake of this project, we will train the model using the first 16 years of data to see how well our forecasted model compares with the test data from 1972.

```{r}
# How I went about finding my dataset from TSDL
subjects <- meta_tsdl %>% 
  group_by(subject) %>% 
  count() %>% 
  arrange(desc(n))

# Filter datasets by meteorology
met <- meta_tsdl %>% 
  filter(subject == 'Meteorology')
```


### Gathering Data

The first thing we'll do after getting the data set is plot the time series with a fitted regression and mean line.

```{r}
# Data found at 'met' index 17
ozone_data <- ts(subset(tsdl, 'Meteorology')[[17]][c(1:216)])
ts.plot(ozone_data)
nt <- length(ozone_data)
fit <- lm(ozone_data ~ as.numeric(1:nt)); abline(fit, col="red")
abline(h=mean(ozone_data), col='blue')

# Create test and training sets
ozone.test <- ts(ozone_data[c(205:216)])
ozone_data <- ts(ozone_data[c(1:204)])
```
We can also visualize how variable the data is at this point through a histogram

```{r}
hist(ozone_data, main='Frequency of Ozone Conc. Per PPM', xlab='Ozone Conc. (PPM)')
```


There's a couple things we notice right off the bat from the original data. The first thing is that the variance does not to be constant throughout the time series, so I'll apply a box-cox transformation to reduce it. The following plots will depict our method of box-cox transformation followed by the transformed time series.

```{r}
t <- 1:length(ozone_data)
fit <- lm(ozone_data ~ t)
bcTransform <- boxcox(ozone_data ~ t, plotit=TRUE)
```

```{r}
# Find best lambda value from graph
lambda <- bcTransform$x[which(bcTransform$y == max(bcTransform$y))]
ozone_bc <- (1/lambda)*(ozone_data^lambda - 1)

# Plot
par(mfrow = c(1,2))
ts.plot(ozone_data, main = "Original data", ylab = expression(X[t]))
ts.plot(ozone_bc, main = "Box-Cox tranformed data", ylab = expression(Y[t]))
```
```{r}
# Histogram of transformed model
hist(ozone_bc, main='Histogram of Transformed Ozone Conc.', 
     xlab='Transformed Ozone Conc. (PPM)')
```

The transformed histogram clearly shows more symmetry and even variance across as it more closely resembles the Gaussian. At this point, we can define $Y_t$ as the set of data corresponding to the box-cox transformed data. Below are the variances for the first data set in comparison to the transformed.

```{r}
# Check to make sure of variance reduction
var(ozone_data)
var(ozone_bc)
```

At this point it may be useful to decompose the elements so that we can see how to proceed.

```{r}
# TS decomposition
y <- ts(as.ts(ozone_bc), frequency = 12)
decomp <- decompose(y)
plot(decomp, xlab = "Time (In Years)")
```

There is a downwards trend that is roughly linear, and there is a clear periodic component. Now we will plot the ACF and PACF.

### Model Identification

First, let's take a look at the ACF and PACF plots from the original series.

```{r}
op <- par(mfrow=c(1,2))
acf(ozone_bc, lag.max = 120)
pacf(ozone_bc, lag.max = 120)
par(op)
```

At this point, we need to go ahead and eliminate the trend in our original data. We also keep in mind here that the ACF graph appears to follow a seasonal pattern with significant spikes every 12 lags.

```{r}
# Difference the time series once to eliminate trend
y1 <- diff(ozone_bc)
plot(y1,main = "De-trended Time Series", ylab = expression(nabla~Y[t]))
abline(h = 0,lty = 2)

fit <- lm(y1 ~ as.numeric(1:length(y1))); abline(fit, col="red")
abline(h=mean(y1), col='blue')
```
There is a clear imporvement in our de-trended series, and we can also now remove seasonality.

```{r}
# Difference this time series at lag 12 to remove seasonality
y12 <- diff(y1, 12)
ts.plot(y12, main = "De-trended/seasonalized Time Series", ylab = 
          expression(nabla^{12}~nabla~Y[t]))
abline(h = 0,lty = 2)

fit <- lm(y12 ~ as.numeric(1:length(y12))); abline(fit, col="red")
abline(h=mean(y12), col='blue')
```


From the above graph our data looks stationary, and now we can check to see how our ACF and PACF graphs have changed as we apply differencing.

```{r}
# Re-calculate the sample variance and examine the ACF and PACF
par(mfrow = c(1,2))
acf(y1,lag.max = 60, main = "")
pacf(y1,lag.max = 60, main = "")
title("De-trended Time Series", line = -1, outer = TRUE)
```

```{r}
# Re-calculate the sample variance and examine the ACF and PACF
par(mfrow = c(1,2))
acf(y12,lag.max = 60,main = "")
pacf(y12,lag.max = 60,main = "")
title("De-trended/seasonalized Time Series", line = -1, outer = TRUE)
```

Here are the things to take note of:

* ACF lags outside of CI at 1, 2, 11, 12, 13, 15
* PACF lags outside of CI at 1, 2, 3, 11, 12, 15, 23

Based on our most recently updated ACF and PACF graphs, we can now begin to attempt fitting a model to the data. 

* Seasonal aspect:
  + We applied one seasonal differencing, so D = 1 and s = 12.
  + The ACF just has a significant peak at h = 1s, so Q should be 1.
  + the PACF shows peaks at h = 1s and 2s, so P could be either 1 or 2.
  
* Non-seasonal aspect:
  + We applied one differencing here, so d = 1.
  + The ACF shows spikes at lags 1 and 2, so q could be 1 or 2.
  + The PACF shows significant spikes at lags 1, 2, and 3, so p should be 3.

### Model Estimation

Now that we have some candidate models to work with, we'll first look at all SMA models and pick out the best one. The below values correspond to setting q=1:2. For reference, all candidate models will have s=12, d=D=1, and Q=1.

```{r}
# SMA models
AICCs <- rep(0,2)

for (i in 1:2) {
  AICCs[i] <- AICc(arima(ozone_bc, order=c(0,1,i), seasonal = list(order = c(0,1,1), period = 12), method="ML"))
}

AICCs

# Check to see if a coefficient can be 0
arima(ozone_bc, order=c(0,1,2), seasonal = list(order = c(0,1,1), period = 12), method="ML")
```
The above call represents the coefficients and the standard errors when setting Q=1 and q=2.

Now we will look at the SAR models. Here, our P=1:2 and p=1:3.

```{r}
# SAR models
AICCs <- matrix(rep(0,6), nrow=2, ncol=3)

for (i in 1:2) {
  for (j in 1:3) {
  AICCs[i,j] <- AICc(arima(ozone_bc, order=c(j,1,0), seasonal = list(order = c(i,1,0), period = 12), method="ML"))
  }
}

AICCs  # All significantly higher than the SMA models
```

Evidently, these are all significantly higher than the SMA models, so we can disregard them.

Lastly, we'll try the SARIMA models with fixed P = 1 and Q = 1. Here our p=1:3 and our q=1:2.

```{r}
# SARIMA models, fix P = 1, Q = 1
AICCs <- matrix(rep(0,6), nrow=2, ncol=3)

for (i in 1:2) {
  for (j in 1:3) {
    AICCs[i,j] <- AICc(arima(ozone_bc, order=c(j,1,i), seasonal = list(order = c(1,1,1), period = 12, method="ML")))
  }
}

AICCs # SARIMA(2,1,1) x (1,1,1) has lowest AICc
```
Our best model had p=q=1, so we can investigate this one further.

```{r}
arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12, method="ML"))
```
Because our sar1 coefficient could be 0 based on the standard error, we will fix it as such.

```{r}
# Check lowest AICC model coefficients
arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12), fixed = c(NA,NA,0,NA), method="ML")
AICc(arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12), fixed = c(NA,NA,0,NA), method="ML"))
```

Based on our findings here, the models we will use are:

* (A) $\nabla_1\nabla_{12}Y_t = (1 - 0.6665_{(0.0713)}B - 0.1985_{(0.0750)}B^2)(1 - 0.7722_{(0.0627)}B^{12})$, $\hat{\sigma}_Z^2 = 0.1348$
* (B) $(1 - 0.2247_{(0.0878)}B)\nabla_1\nabla_{12}Y_t = (1 - 0.9026_{(0.0484)}B)(1 - 0.7763_{(0.0625)}B^{12})$, $\hat{\sigma}_Z^2 = 0.1347$

### Model Diagnostics

We know that both models are stationary and invertible as the absolute value of all coefficients in either are strictly less than 1.

```{r}
# Model fits
fit.a <- arima(ozone_bc, order=c(0,1,2), seasonal = list(order = c(0,1,1), period = 12),
               method="ML")
fit.b <- arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12), fixed = c(NA,NA,0,NA), method="ML")

# Residuals
res.a <- residuals(fit.a)
res.b <- residuals(fit.b)
```

Now we can do diagnostic checking on each model by performing fitted vs. residuals, QQ-plot, fitting a histogram, and doing a Shapiro-Wilk test on the model residuals.

```{r}
# Model A checks

# Fitted vs. Residuals
ts.plot(res.a, main = "Fitted Residuals")
t = 1:length(res.a)
fit.res.a = lm(res.a~t)
abline(fit.res.a)
abline(h = mean(res.a), col = "red")

# Histogram
hist(res.a)

# QQ plot
qqnorm(res.a)
qqline(res.a, col='blue')

# Shapiro-Wilk
shapiro.test(res.a)  # p-value > 0.05
```

Model A fits our first 4 diagnostic procedures, so it will pass and we move on to Model B.

```{r}
# Model B checks

# Fitted vs. Residuals
ts.plot(res.b, main = "Fitted Residuals")
t = 1:length(res.b)
fit.res.b = lm(res.b~t)
abline(fit.res.b)
abline(h = mean(res.b), col = "red")

# Histogram
hist(res.b)

# QQ plot
qqnorm(res.b)
qqline(res.b, col='blue')

# Shapiro-Wilk
shapiro.test(res.b)  # p-value > 0.05
```

Model B also passes the first 4 diagnostic procedures, so we will move on to Portmanteau testing. Our sample data consists of 204 observations, and $\sqrt(204) \approx 14$, so h = 14.

```{r}
# Model A
Box.test(res.a, lag=14, type = c("Box-Pierce"), fitdf = 3)
Box.test(res.a, lag=14, type = c("Ljung-Box"), fitdf = 3)
Box.test((res.a)^2, lag = 14, type = c("Ljung-Box"), fitdf = 0)
```

All Portmanteau tests had p-values greater than 0.05, so this model passes.

```{r}
# Model B
Box.test(res.b, lag=14, type = c("Box-Pierce"), fitdf = 3)
Box.test(res.b, lag=14, type = c("Ljung-Box"), fitdf = 3)
Box.test((res.b)^2, lag = 14, type = c("Ljung-Box"), fitdf = 0)
```

Again all tests pass, and so we can go ahead and check the ACF and PACF plots of the residuals.
The first row shows Model A whle the second row shows Model B.

```{r}
par(mfrow = c(2,2))
acf(res.a, main ='')
pacf(res.a, main='')
acf(res.b, main='')
pacf(res.b, main='')
```

Since both models passed all diagnostic testing and have the same number of parameters, we will choose Model A as it's AICc is slightly lower than Model B's. We can now move on to forecasting now that we have chosen an appropriate model.

# Model Forecasting

Model: $\nabla_1\nabla_{12}Y_t = (1 - 0.6665_{(0.0713)}B - 0.1985_{(0.0750)}B^2)(1 - 0.7722_{(0.0627)}B^{12})$, $\hat{\sigma}_Z^2 = 0.1348$

Now we want to forecast on the transformed data to see what it would look like.

```{r}
final.fit <- arima(ozone_bc, order=c(0,1,2), seasonal = list(order = c(0,1,1), period = 12),
                   method="ML")
```

```{r}
pred.tr <- predict(final.fit, n.ahead=12)
U.tr <- pred.tr$pred + 2*pred.tr$se
L.tr <- pred.tr$pred - 2*pred.tr$se

ts.plot(ozone_bc, xlim=c(1,length(ozone_bc)+12), ylim=c(-1,4), 
        ylab="Transformed Ozone Conc. (PPM)")
lines(U.tr, col="blue", lty="dashed")
lines(L.tr, col="blue", lty="dashed")
points((length(ozone_bc)+1):(length(ozone_bc)+12), pred.tr$pred, col="red")
```

Now we can proceed to check what our forecast would look like on our original data.

```{r}
final.fit.orig <- arima(ozone_data, order=c(0,1,2), 
                        seasonal = list(order = c(0,1,1), period = 12), method="ML")
```


```{r}
pred.orig <- predict(final.fit.orig, n.ahead=12)
U <- pred.orig$pred + 2*pred.orig$se
L <- pred.orig$pred - 2*pred.orig$se

ts.plot(ozone_data, xlim=c(1,length(ozone_data)+12), ylim=c(-1,9), ylab="Ozone Conc. (PPM)")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(ozone_data)+1):(length(ozone_data)+12), pred.orig$pred, col="red")
```

It may be easier if we zoom in from time 150 to see what the forecast looks like.

```{r}
ts.plot(ozone_data, xlim=c(150,length(ozone_data)+12), ylim=c(-1,9), ylab="Ozone Conc. (PPM)")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(ozone_data)+1):(length(ozone_data)+12), pred.orig$pred, col="red")
```

Finally, we can compare the points in our prediction interval with the test training set.

```{r}
full_set <- ts(subset(tsdl, 'Meteorology')[[17]][c(1:216)])

ts.plot(full_set, xlim=c(150,length(ozone_data)+12), ylim=c(-1,9), ylab="Ozone Conc. (PPM)")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(ozone_data)+1):(length(ozone_data)+12), pred.orig$pred, col="red")
```


### Conclusions

The purpose of this project was to take collected data of ozone concentration (ppm) and use it to forecast following concentrations. We decided that the best fitting model for this data was a SARIMA(0,1,1) x (0,1,2)$_{12}$, which we then used to forecast simulated data in comparison to test data that we already had. As the consequences of climate change continue to ramp up, it could be useful to have benchmark models such as this one where we can check levels of ozone and the trend it follows. This data ranges from 1955 to 1972, so the model could potentially be outdated, but if we continued to follow the model as it was, ozone levels would continuously drop lower and lower each year. This is certainly problematic as having ozone in the atmosphere keeps our base temperature less variable, and having data that shows our current trend could be a powerful visualization tool in showing those who don't understand the problem that it is something that will lead to inevitable demise if the people of the world continue to operate in the same manner.

For the sake of the model, this was a successful forecasting as our test data was completely contained within the bounds of our 95% confidence interval. It would be interesting to see how far in advance this model could accurately forecast before becoming obsolete.

### References

R Time Series Data Library, Rob J Hyndman

### Appendix

```{r, eval=F, echo=T}
knitr::opts_chunk$set(echo = F,
                      eval = T,
                      message = F,
                      warning = F,
                      fig.height = 4,
                      fig.width = 6,
                      fig.align = 'center')
library(tidyverse)
library(modelr)
library(dplyr)
library(ggplot2)
library(ggfortify)
library(readr)
library(tsdl)
library(astsa)
library(MASS)
library(MuMIn)
library(forecast)


# How I went about finding my dataset from TSDL
subjects <- meta_tsdl %>% 
  group_by(subject) %>% 
  count() %>% 
  arrange(desc(n))

# Filter datasets by meteorology
met <- meta_tsdl %>% 
  filter(subject == 'Meteorology')


# Data found at 'met' index 17
ozone_data <- ts(subset(tsdl, 'Meteorology')[[17]][c(1:216)])
ts.plot(ozone_data)
nt <- length(ozone_data)
fit <- lm(ozone_data ~ as.numeric(1:nt)); abline(fit, col="red")
abline(h=mean(ozone_data), col='blue')

# Create test and training sets
ozone.test <- ts(ozone_data[c(205:216)])
ozone_data <- ts(ozone_data[c(1:204)])

# histogram of original data
hist(ozone_data, main='Frequency of Ozone Conc. Per PPM', xlab='Ozone Conc. (PPM)')

# box cox transform
t <- 1:length(ozone_data)
fit <- lm(ozone_data ~ t)
bcTransform <- boxcox(ozone_data ~ t, plotit=TRUE)

# Find best lambda value from graph
lambda <- bcTransform$x[which(bcTransform$y == max(bcTransform$y))]
ozone_bc <- (1/lambda)*(ozone_data^lambda - 1)

# Plot
par(mfrow = c(1,2))
ts.plot(ozone_data, main = "Original data", ylab = expression(X[t]))
ts.plot(ozone_bc, main = "Box-Cox tranformed data", ylab = expression(Y[t]))

# Histogram of transformed model
hist(ozone_bc, main='Histogram of Transformed Ozone Conc.', 
     xlab='Transformed Ozone Conc. (PPM)')

# Check to make sure of variance reduction
var(ozone_data)
var(ozone_bc)

# TS decomposition
y <- ts(as.ts(ozone_bc), frequency = 12)
decomp <- decompose(y)
plot(decomp, xlab = "Time (In Years)")

# Original P/ACF
op <- par(mfrow=c(1,2))
acf(ozone_bc, lag.max = 120)
pacf(ozone_bc, lag.max = 120)
par(op)

# Difference the time series once to eliminate trend
y1 <- diff(ozone_bc)
plot(y1,main = "De-trended Time Series", ylab = expression(nabla~Y[t]))
abline(h = 0,lty = 2)

fit <- lm(y1 ~ as.numeric(1:length(y1))); abline(fit, col="red")
abline(h=mean(y1), col='blue')

# Difference this time series at lag 12 to remove seasonality
y12 <- diff(y1, 12)
ts.plot(y12, main = "De-trended/seasonalized Time Series", ylab = 
          expression(nabla^{12}~nabla~Y[t]))
abline(h = 0,lty = 2)

fit <- lm(y12 ~ as.numeric(1:length(y12))); abline(fit, col="red")
abline(h=mean(y12), col='blue')

# Re-calculate the sample variance and examine the ACF and PACF
par(mfrow = c(1,2))
acf(y1,lag.max = 60, main = "")
pacf(y1,lag.max = 60, main = "")
title("De-trended Time Series", line = -1, outer = TRUE)

# Re-calculate the sample variance and examine the ACF and PACF
par(mfrow = c(1,2))
acf(y12,lag.max = 60,main = "")
pacf(y12,lag.max = 60,main = "")
title("De-trended/seasonalized Time Series", line = -1, outer = TRUE)

# SMA models
AICCs <- rep(0,2)

for (i in 1:2) {
  AICCs[i] <- AICc(arima(ozone_bc, order=c(0,1,i), seasonal = list(order = c(0,1,1), period = 12), method="ML"))
}

AICCs

# Check to see if a coefficient can be 0
arima(ozone_bc, order=c(0,1,2), seasonal = list(order = c(0,1,1), period = 12), method="ML")


# SAR models
AICCs <- matrix(rep(0,6), nrow=2, ncol=3)

for (i in 1:2) {
  for (j in 1:3) {
  AICCs[i,j] <- AICc(arima(ozone_bc, order=c(j,1,0), seasonal = list(order = c(i,1,0), period = 12), method="ML"))
  }
}

AICCs  # All significantly higher than the SMA models


# SARIMA models, fix P = 1, Q = 1
AICCs <- matrix(rep(0,6), nrow=2, ncol=3)

for (i in 1:2) {
  for (j in 1:3) {
    AICCs[i,j] <- AICc(arima(ozone_bc, order=c(j,1,i), seasonal = list(order = c(1,1,1), period = 12, method="ML")))
  }
}

AICCs # SARIMA(2,1,1) x (1,1,1) has lowest AICc

arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12, method="ML"))

# Check lowest AICC model coefficients
arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12), fixed = c(NA,NA,0,NA), method="ML")
AICc(arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12), fixed = c(NA,NA,0,NA), method="ML"))


# Model fits
fit.a <- arima(ozone_bc, order=c(0,1,2), seasonal = list(order = c(0,1,1), period = 12),
               method="ML")
fit.b <- arima(ozone_bc, order=c(1,1,1), seasonal = list(order = c(1,1,1), period = 12), fixed = c(NA,NA,0,NA), method="ML")

# Residuals
res.a <- residuals(fit.a)
res.b <- residuals(fit.b)


# Model A checks

# Fitted vs. Residuals
ts.plot(res.a, main = "Fitted Residuals")
t = 1:length(res.a)
fit.res.a = lm(res.a~t)
abline(fit.res.a)
abline(h = mean(res.a), col = "red")

# Histogram
hist(res.a)

# QQ plot
qqnorm(res.a)
qqline(res.a, col='blue')

# Shapiro-Wilk
shapiro.test(res.a)  # p-value > 0.05


# Model B checks

# Fitted vs. Residuals
ts.plot(res.b, main = "Fitted Residuals")
t = 1:length(res.b)
fit.res.b = lm(res.b~t)
abline(fit.res.b)
abline(h = mean(res.b), col = "red")

# Histogram
hist(res.b)

# QQ plot
qqnorm(res.b)
qqline(res.b, col='blue')

# Shapiro-Wilk
shapiro.test(res.b)  # p-value > 0.05


# Model A
Box.test(res.a, lag=14, type = c("Box-Pierce"), fitdf = 3)
Box.test(res.a, lag=14, type = c("Ljung-Box"), fitdf = 3)
Box.test((res.a)^2, lag = 14, type = c("Ljung-Box"), fitdf = 0)

# Model B
Box.test(res.b, lag=14, type = c("Box-Pierce"), fitdf = 3)
Box.test(res.b, lag=14, type = c("Ljung-Box"), fitdf = 3)
Box.test((res.b)^2, lag = 14, type = c("Ljung-Box"), fitdf = 0)

# Visualize P/ACF
par(mfrow = c(2,2))
acf(res.a, main ='')
pacf(res.a, main='')
acf(res.b, main='')
pacf(res.b, main='')

# Confirm model
final.fit <- arima(ozone_bc, order=c(0,1,2), seasonal = list(order = c(0,1,1), period = 12),
                   method="ML")

# Forecast on Model
pred.tr <- predict(final.fit, n.ahead=12)
U.tr <- pred.tr$pred + 2*pred.tr$se
L.tr <- pred.tr$pred - 2*pred.tr$se

ts.plot(ozone_bc, xlim=c(1,length(ozone_bc)+12), ylim=c(-1,4), 
        ylab="Transformed Ozone Conc. (PPM)")
lines(U.tr, col="blue", lty="dashed")
lines(L.tr, col="blue", lty="dashed")
points((length(ozone_bc)+1):(length(ozone_bc)+12), pred.tr$pred, col="red")

# Use original data
final.fit.orig <- arima(ozone_data, order=c(0,1,2), 
                        seasonal = list(order = c(0,1,1), period = 12), method="ML")

# Forecast on model
pred.orig <- predict(final.fit.orig, n.ahead=12)
U <- pred.orig$pred + 2*pred.orig$se
L <- pred.orig$pred - 2*pred.orig$se

ts.plot(ozone_data, xlim=c(1,length(ozone_data)+12), ylim=c(-1,9), ylab="Ozone Conc. (PPM)")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(ozone_data)+1):(length(ozone_data)+12), pred.orig$pred, col="red")

# Zoom in
ts.plot(ozone_data, xlim=c(150,length(ozone_data)+12), ylim=c(-1,9), ylab="Ozone Conc. (PPM)")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(ozone_data)+1):(length(ozone_data)+12), pred.orig$pred, col="red")

# Compare train and test
full_set <- ts(subset(tsdl, 'Meteorology')[[17]][c(1:216)])

ts.plot(full_set, xlim=c(150,length(ozone_data)+12), ylim=c(-1,9), ylab="Ozone Conc. (PPM)")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(ozone_data)+1):(length(ozone_data)+12), pred.orig$pred, col="red")
```

